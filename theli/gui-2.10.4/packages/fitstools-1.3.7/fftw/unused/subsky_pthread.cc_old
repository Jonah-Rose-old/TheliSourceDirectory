#include <CCfits>
#include <thread>
#include <mutex>
#include <fitsio.h>
#include <fftw3.h>
#include "fftw++.h"
#include "convolve.h"
#include "fitstools.h"
#include "statistics.h"

using namespace std;

void globalstats(vector<float>&, vector<float>&, int, int, float*, float*);
void get_objectsize(vector<float>&, long, long, vector<long>&);
void floodfill(vector<float>&, vector<float>&, float, long, long, long, long, long);
void fill_objects(vector<float>&, vector<float>&, vector<float>&, long, long, long, int);
void clean_image(vector<float>&, myFITS&, float, float, int, float, int);
void *clean_image_thread(void *);
void *fill_objects_thread(void *);

// the thread arguments
struct thread_data
{
  long n, m, line_start, line_end, npix;
  vector<float> data, seg, image_back;
  vector<long> objectsize;
};

struct thread_data2
{
  long n, m, line_start, line_end;
  float lthresh_out, hthresh_out, global_median;
  vector<float> image, *seg, segcopy;
  vector<long> objectsize;
};


void usage(int i, char *argv[])
{
  if (i == 0) {
    cerr << "\n";
    cerr << "  USAGE: " << argv[0] << endl;
    cerr << "           -i input_image \n";
    cerr << "           -s segmentation_image \n";
    cerr << "           -n number of pixels used for estimation (default: 100)\n";
    cerr << "           -f FWHM of the smoothing kernel in pixels\n";
    cerr << "           -c number of CPUs to use\n";
    cerr << "           [-o output_image]\n";
    cerr << "           [-m model_image]\n";
    cerr << "           [-w weight_image]\n";
    cerr << "           [-p ds9-mask]\n";
    cerr << "           [-t minthresh maxthresh (manual thresholding)]\n";
    cerr << "           [-k sigma clip for the threshold (default: 5)]\n\n";
    cerr << "           [-d (do not use FFTW wisdom)]\n";
    cerr << "    Replaces objects (defined in a segmentation image)\n";
    cerr << "    with a local background estimate. The latter is obtained\n";
    cerr << "    from the -n nearest background pixels (automatically adjusted).\n\n";
    cerr << "    Optionally, a ds9 region file can be specified. Pixels in polygons\n";
    cerr << "    and circles therein will be kept or masked, depending on the 'sense'\n";
    cerr << "    of the ds9 region file. The latter is defined through this comment line:\n";
    cerr << "    # Sense: in|out\n\n";

    exit(1);
  }
}

int main(int argc, char *argv[])
{
  int n, m, flag_mt, flag_w, flag_ds9, ncpu, nthreads, nthreads_user;
  long i, npix;
  float lowthresh, highthresh, fwhm, clip, maxval;
  string input_image, seg_image, weight_image, output_image, model_image;
  char ds9region[FILEMAX];

  // print usage if no arguments were given
  flag_mt  = 0;
  flag_w   = 0;
  flag_ds9 = 0;
  clip     = 5.;
  npix     = 100;
  fwhm     = 0.;
  lowthresh  = 0.;
  highthresh = 0.;
  nthreads_user = 0;

  fftwpp::fftw::effort = FFTW_MEASURE;

  if (argc==1) usage(0, argv);

  for (i=1; i<argc; i++) {
    if (argv[i][0] == '-') {
      switch(tolower((int)argv[i][1])) {
      case 'i': input_image = argv[++i];
	break;
      case 's': seg_image = argv[++i];
	break;
      case 'm': model_image = argv[++i];
	break;
      case 'w': weight_image = argv[++i];
	flag_w = 1;
	break;
      case 'o': output_image = argv[++i];
	break;
      case 'n': npix = atol(argv[++i]);
	break;
      case 'd': fftwpp::fftw::effort = FFTW_ESTIMATE;
	break;
      case 't': 
	lowthresh  = atof(argv[++i]);
	highthresh = atof(argv[++i]);
	flag_mt = 1;
	break;
      case 'k': clip = atof(argv[++i]);
	break;
      case 'f': fwhm = atof(argv[++i]);
	break;
      case 'c': nthreads_user = atoi(argv[++i]);
	break;
      case 'p': strcpy(ds9region,argv[++i]);
	flag_ds9 = 1;
	break;
      }
    } 
  }

  if (fwhm < 2.) {
    cerr <<  "ERROR: The FWHM of the smoothing kernel was not specified\n";
    cerr <<  "       or is smaller than 2. Exiting.\n";
    exit (1);
  }

  // multi-threading
  ncpu = sysconf(_SC_NPROCESSORS_ONLN);
  nthreads = ncpu;
  if (nthreads_user > 0) {
    if (nthreads_user > ncpu) nthreads = ncpu;
    else nthreads = nthreads_user;
  }

  // Read the FITS images
  checkfile(input_image);
  string call = programcall(argv, argc);

  myFITS image_in(input_image);
  myFITS image_seg(seg_image);
  n = image_in.naxis1;
  m = image_in.naxis2;
  
  // a copy of the input image
  vector<float> image(image_in.data);

  // the image with objects replaced by a dynamic background estimate
  vector<float> image_back(n*m,0);

  vector<int> mask(n*m,0);

  // write the result

  // remove spurious pixels from the image
  clean_image(image, image_seg, lowthresh, highthresh, flag_mt, clip, nthreads);

  writeImage("clean.fits", input_image, image, call);
  writeImage("segfilt.fits", input_image, image_seg.data, call);

  // apply a ds9 region mask file to the segmentation image, if requested
  if (flag_ds9 == 1) {
    maxval = max(image_seg.data, n*m);

    // the empty strings mean we use keywords in the ds9 region file
    make_ds9_maskimage(mask, ds9region, n, m, "", "");
    
    // complement the segmentation image with the polygon mask;
    // we assume the mask is zero for bad and 1 for good pixels
    for (i=0; i<n*m; i++) {
      if (mask[i] == 0) image_seg.data[i] = maxval + 1;
    }
  }
  
  if (flag_w == 1) {
    maxval = max(image_seg.data, n*m);
    myFITS image_w(weight_image);
    for (i=0; i<n*m; i++) {
      if (image_w.data[i] == 0.) image_seg.data[i] = maxval + 1;
    }
  }

  // replace objects with dynamic background
  // fill_objects(image, image_seg.data, image_back, n, m, npix, nthreads);

  for (i=0; i<n*m; i++) {
    if (image_seg.data[i] == 0.) image_back[i] = image[i];
  }

  //  for (int i=0; i<n*m; i++) data_out[i] = image_back.data[i];
  //  for (i=0; i<n*m; i++) data_out[i] = image_seg.data[i];
  //image_save_fits(image_out, "step2.fits", BPP_IEEE_FLOAT);
  //writeImage("test2.fits", input_image, image_back, call);
  
  // convolve the image with a gaussian
  convolve_gauss_2d(image_back, n, m, fwhm, nthreads);
  
  vector<float> data_out(n*m,0);

  if (flag_ds9 == 0) {
    for (i=0; i<n*m; i++) 
      data_out[i] = image_in.data[i] - image_back[i];
  }
  if (flag_ds9 == 1) {
    for (i=0; i<n*m; i++) 
      data_out[i] = (image_in.data[i] - image_back[i]) * mask[i];
  }

  writeImage(output_image, input_image, data_out, call);
  
  if (!model_image.empty()) {
    for (i=0; i<n*m; i++) data_out[i] = image_back[i];
    writeImage(model_image, input_image, data_out, call);
  }

  return 0;
}

//************************************************************
void globalstats(vector<float> &data, vector<float> &seg, int n, int m, 
		 float &globmedian, float &globrms)
{
  int l, t, j;
  long dim_small, dim, dim90, i;
  
  // define some odd number
  // then select every l-th pixel in the array
  // that is always smaller than n for n > 9
  // the sqrt ensures that the array is probed in a quasi-random pattern
  
  l = 2/3*n + sqrt(n); 
  
  // the number of elements we test
  dim = n * m;
  dim_small = dim / l;
  
  vector<float> sub(dim_small,0);
  
  // select the small array
  t = 0;
  j = 0;
  for (i=0; i<dim; i++) {
    if (t==0 && j < dim_small && seg[i] == 0) {
      sub[j] = data[i];
      j++;
    }
    if (t<l) t++;
    if (t == l) t = 0;
  }
  
  // sort the array
  sort(sub.begin(), sub.begin()+j-1);
  
  // get the rms from the middle 90%    
  dim90 = 0;
  for (i=0.05*j; i<0.95*j; i++) {
    dim90++;
  }
  vector<float> arr90(dim90,0);
  dim90 = 0;
  for (i=0.05*j; i<0.95*j; i++) {
    arr90[dim90++] = sub[i];
  }
  
  globmedian = median(arr90, dim90);
  globrms  = rms(arr90, dim90);
}


//***************************************************************
// count how large the individual objects are
//***************************************************************
void get_objectsize(vector<float> &data, long n, long m, vector<long> &objectsize)
{
  long i;

  // the number of pixels in each object
  for (i=0; i<n*m; i++) {
    if (data[i] != 0) objectsize[(long) data[i] - 1]++;
  }
}


//***************************************************************
// This function replaces neighbouring pixels around a given pixel
// with the same value assigned to this pixel.
// Like that big objects can be filled rapidly.
// The larger the object, the more pixels we fill in
//***************************************************************

void floodfill(vector<float>&data, vector<float>&seg, float value, long n, 
	       long m, long i, long j, long size)
{
  long imin, imax, jmin, jmax;
  long range;
  long i1, j1;

  range = sqrt(size) / 3;
  if (range < 4) range = 4;

  imin = i-range;
  imax = i+range;
  jmin = j-range;
  jmax = j+range;

  // respect image boundaries
  if (imin  < 0) imin = 0;
  if (imax >= n) imax = n-1;
  if (jmin  < 0) jmin = 0;
  if (jmax >= m) jmax = m-1;

  for (j1=jmin; j1<=jmax; j1++) {
    for (i1=imin; i1<=imax; i1++) {
      if (seg[i1+n*j1] != 0) data[i1+n*j1] = value;
    }
  }
}

//********************************************************************
// This function interpolates pixels in the image which are non-zero 
// in the segmentation image, by a local background estimate.
// The interpolated pixel value within an object will vary, meaning
// this yields good values also for large objects with varying 
// background 
//********************************************************************

void fill_objects(vector<float> &data, vector<float> &seg, vector<float> &image_back, 
		  long n, long m, long npix, int NUM_THREADS)
{
  vector<long> objectsize(n*m,0);

  // get the object sizes
  get_objectsize(seg, n, m, objectsize);

  struct thread_data *thread_data_array = new thread_data[NUM_THREADS];

  // the threads
  pthread_t *threads = new pthread_t[NUM_THREADS];
  int t, rc;

  // create arguments and launch threads
  for(t=0; t<NUM_THREADS; t++) {
    thread_data_array[t].n = n;
    thread_data_array[t].m = m;
    thread_data_array[t].npix = npix;
    thread_data_array[t].line_start = t * (m / NUM_THREADS);
    if (t <  NUM_THREADS-1) thread_data_array[t].line_end = (t + 1) * (m / NUM_THREADS) - 1;
    if (t == NUM_THREADS-1) thread_data_array[t].line_end = m - 1;
    thread_data_array[t].data = data;
    thread_data_array[t].seg = seg;
    thread_data_array[t].image_back = image_back;
    thread_data_array[t].objectsize = objectsize;

    rc = pthread_create(&threads[t], NULL, fill_objects_thread, 
    			(void *) &thread_data_array[t]);
    if (rc) {
      printf("ERROR; return code from pthread_create() is %d\n", rc);
      exit(-1);
    }
  }

  // wait for threads to finish
  for (t=0; t<NUM_THREADS; t++)
    pthread_join( threads[t], NULL );

}


//*******************************************************************
// fill objects with a background estimate;
// this will be called from multiple threads
//*******************************************************************

void *fill_objects_thread(void *threadarg)
{
  long count, i, j, jstart, jend, npix, size, npixlocal;
  long imin, imax, jmin, jmax, i1, j1, n, m;
  long radius, delta_rad;
  float value;

  struct thread_data *my_data;
  
  my_data = (struct thread_data *) threadarg;

  jstart = my_data->line_start;
  jend   = my_data->line_end;
  npix   = my_data->npix;
  n      = my_data->n;
  m      = my_data->m;

  vector<float> tmpnpix(npix,0);

  // fill objects
  count = 0;
  for (j=jstart; j<=jend; j++) {
    for (i=0; i<n; i++) {
      if (my_data->seg[i+n*j] > 0. && my_data->image_back[i+n*j] == 0.) {
	// dynamic estimate for the number of good pixels
	size = my_data->objectsize[(long) (my_data->seg[i+n*j]) - 1];
	npixlocal = 3 * size;
	if (npixlocal > npix) npixlocal = npix;
	// we add 5 to the radius to make sure it is larger than 0 
	// (and to quickly jump over the small objects)

	radius = sqrt( (float) npixlocal / PI) + 5;
	while (count < npixlocal) {
	  imin = i - radius;
	  imax = i + radius;
	  jmin = j - radius;
	  jmax = j + radius;
	  // respect image boundaries
	  if (imin  < 0) imin = 0;
	  if (imax >= n) imax = n;
	  if (jmin  < 0) jmin = 0;
	  if (jmax >= m) jmax = m;
	  for (j1=jmin; j1<jmax; j1++) {
	    for (i1=imin; i1<imax; i1++) {
	      if (my_data->seg[i1+n*j1] == 0. && count < npixlocal) {
		tmpnpix[count] = my_data->data[i1+n*j1];
		count++;
	      }
	    }
	  }
	  
	  if (count<npixlocal) {
	    // estimate by how much we have to increase the radius to get npix good pixels
	    delta_rad = (npixlocal - count + radius * radius * PI) / PI;
	    if (delta_rad < 0) radius *= 1.1;
	    else {
	      delta_rad = sqrt( (float) delta_rad ) - radius + 5;
	      radius += delta_rad;
	    }
	  }
	}
	value = mean(tmpnpix, (long) (0.7*npixlocal));
	// The threads can overwrite data in the floodfill routine, hence this is
	// not threadsafe. However, the values are guesswork anyway so it doesn't matter
	// from which thread the estimate comes.
	floodfill(my_data->image_back, my_data->seg, value, n, m, i, j, size);
      } 
      if (my_data->seg[i+n*j] == 0. && my_data->image_back[i+n*j] == 0.)
	my_data->image_back[i+n*j] = my_data->data[i+n*j];
      count = 0;
    }
  }

  pthread_exit(NULL);
}


// ***********************************************************
// remove spurious pixels
void clean_image(vector<float> &image, myFITS &image_seg, float lthresh, 
		float hthresh, int flag, float clip, int NUM_THREADS)
{
  long i, nobjects, n, m;
  float global_median, global_rms, lthresh_out, hthresh_out;

  n = image_seg.naxis1;
  m = image_seg.naxis2;

  nobjects = max(image_seg.data, n*m);
  
  // automatic thresholding, if no manual thresholds are provided
  globalstats(image, image_seg.data, n, m, global_median, global_rms);

  cout << "globmean globrms: " << global_median << " " << global_rms << endl;

  lthresh_out = global_median - 0.65 * clip * global_rms;
  hthresh_out = global_median + 1.00 * clip * global_rms;

  // if a manual threshold is provided, add the correspondingly 
  // masked pixels to the segmentation map
  if (flag == 1) {
    for (i=0; i<n*m; i++) {
      if (image[i] < lthresh || image[i] > hthresh) 
	image_seg.data[i] = nobjects + 1;
    }
  }

  // get the object sizes
  vector<long> objectsize(n*m,0);
  get_objectsize(image_seg.data, n, m, objectsize);

  // make a copy of the segmentation image
  vector<float> segcopy(image_seg.data);

  // PREPARE THREADS
  struct thread_data2 *thread_data_array2 = new thread_data2[NUM_THREADS];

  // THE THREADS
  pthread_t *threads = new pthread_t[NUM_THREADS];
  int t, rc;

  // create arguments and launch threads
  for(t=0; t<NUM_THREADS; t++) {
    thread_data_array2[t].n = n;
    thread_data_array2[t].m = m;
    thread_data_array2[t].lthresh_out = lthresh_out;
    thread_data_array2[t].hthresh_out = hthresh_out;
    thread_data_array2[t].line_start = t * (m / NUM_THREADS);
    thread_data_array2[t].image = image;
    thread_data_array2[t].seg = &image_seg.data;
    thread_data_array2[t].objectsize = objectsize;
    thread_data_array2[t].segcopy = segcopy;
    thread_data_array2[t].global_median = global_median;
    if (t <  NUM_THREADS-1) thread_data_array2[t].line_end = (t + 1) * (m / NUM_THREADS) - 1;
    if (t == NUM_THREADS-1) thread_data_array2[t].line_end = m - 1;

    rc = pthread_create(&threads[t], NULL, clean_image_thread, 
    			(void *) &thread_data_array2[t]);
    if (rc) {
      printf("ERROR; return code from pthread_create() is %d\n", rc);
      exit(-1);
    }
  }

  // wait for threads to finish
  for (t=0; t<NUM_THREADS; t++) {
    if (pthread_join( threads[t], NULL ) != 0) {
      printf("ERROR joining threads!\n");
      exit (1);
    }
  }
  writeImage("segexpanded.fits", image_seg.data, n, m, -32);
}


//**************************************************************
void *clean_image_thread(void *threadarg)
{
  float lthresh_out, hthresh_out;
  long masklinemin, masklinemax, maskcolmin, maskcolmax, maskwidth=2, l, o;
  int i1, i2, j1, j2, i0, j0, count_h, count_l;
  long jstart, jend, n, m, i, j, size;

  struct thread_data2 *my_data;
  my_data = (struct thread_data2 *) threadarg;

  jstart = my_data->line_start;
  jend   = my_data->line_end;
  n      = my_data->n;
  m      = my_data->m;
  lthresh_out = my_data->lthresh_out;
  hthresh_out = my_data->hthresh_out;

  // wrap a 'maskwidth' wide border around all objects in the segmentation image
  for (j=jstart; j<=jend; j++) {
    for (i=0; i<n; i++) {
      if (my_data->segcopy[i+n*j] != 0) {
	size = my_data->objectsize[(long) (my_data->segcopy[i+n*j]) - 1];
	maskwidth = sqrt((float) size) / PI;
	if (maskwidth > 20) maskwidth = 20;
	masklinemin = (j - maskwidth) < 0 ? 0 : (j - maskwidth);
	masklinemax = (j + maskwidth) > (m - 1) ? (m - 1) : (j + maskwidth);
	maskcolmin  = (i - maskwidth) < 0 ? 0 : (i - maskwidth);
	maskcolmax  = (i + maskwidth) > (n - 1) ? (n - 1) : (i + maskwidth);
	for (l = masklinemin; l <= masklinemax; l++) {
	  for (o = maskcolmin; o <= maskcolmax; o++) {
	    my_data->seg[o+(l*n)] = my_data->segcopy[i+n*j];
	  }
	}
      }
    }
  }

  // remove spurious pixels; filter out only isolated pixels
  // max only 2 bad neighbors allowed
  for (j=jstart; j<=jend; j++) {
    j1 = j-1;
    j2 = j+1;
    if (j1<0) j1=0;
    if (j2==m) j2=m-1;
    for (i=0; i<n; i++) {
      i1 = i-1;
      i2 = i+1;
      if (i1<0) i1=0;
      if (i2==n) i2=n-1;
      // count how many of the 8 surrounding pixels (and the center one) are bad
      count_h = 0;
      count_l = 0;
      for (j0=j1; j0<=j2; j0++) {
	for (i0=i1; i0<=i2; i0++) {
	  if (my_data->image[i0+n*j0] > hthresh_out) count_h++;
	  if (my_data->image[i0+n*j0] < lthresh_out) count_l++;
	}
      }
      if ((my_data->image[i+n*j] > hthresh_out && count_h <= 3) || 
	  (my_data->image[i+n*j] < lthresh_out && count_l <= 9)) {
	my_data->image[i+n*j] = my_data->global_median;
      }
    } 
  }

  pthread_exit(NULL);
}
